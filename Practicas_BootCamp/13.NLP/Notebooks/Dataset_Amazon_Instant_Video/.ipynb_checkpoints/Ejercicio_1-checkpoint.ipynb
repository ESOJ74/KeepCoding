{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac2c829",
   "metadata": {},
   "source": [
    "# Ejercicio 1 - Descarga y exploración del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8116e",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2329c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from nltk import RegexpTokenizer\n",
    "from collections import Counter\n",
    "from stop_words import get_stop_words\n",
    "from nltk import ngrams\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from num2words import num2words\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f75b6",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f6370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-13 18:58:29--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Amazon_Instant_Video_5.json.gz\n",
      "Resolviendo snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
      "Conectando con snap.stanford.edu (snap.stanford.edu)[171.64.75.80]:80... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 9517526 (9,1M) [application/x-gzip]\n",
      "Guardando como: “reviews_Amazon_Instant_Video_5.json.gz”\n",
      "\n",
      "reviews_Amazon_Inst 100%[===================>]   9,08M   271KB/s    en 44s     \n",
      "\n",
      "2022-02-13 18:59:14 (210 KB/s) - “reviews_Amazon_Instant_Video_5.json.gz” guardado [9517526/9517526]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11N155CW1UV02</td>\n",
       "      <td>B000H00VBQ</td>\n",
       "      <td>AdrianaM</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I had big expectations because I love English ...</td>\n",
       "      <td>2</td>\n",
       "      <td>A little bit boring for me</td>\n",
       "      <td>1399075200</td>\n",
       "      <td>05 3, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3BC8O2KCL29V2</td>\n",
       "      <td>B000H00VBQ</td>\n",
       "      <td>Carol T</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I highly recommend this series. It is a must f...</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent Grown Up TV</td>\n",
       "      <td>1346630400</td>\n",
       "      <td>09 3, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A60D5HQFOTSOM</td>\n",
       "      <td>B000H00VBQ</td>\n",
       "      <td>Daniel Cooper \"dancoopermedia\"</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>This one is a real snoozer. Don't believe anyt...</td>\n",
       "      <td>1</td>\n",
       "      <td>Way too boring for me</td>\n",
       "      <td>1381881600</td>\n",
       "      <td>10 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1RJPIGRSNX4PW</td>\n",
       "      <td>B000H00VBQ</td>\n",
       "      <td>J. Kaplan \"JJ\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Mysteries are interesting.  The tension betwee...</td>\n",
       "      <td>4</td>\n",
       "      <td>Robson Green is mesmerizing</td>\n",
       "      <td>1383091200</td>\n",
       "      <td>10 30, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A16XRPF40679KG</td>\n",
       "      <td>B000H00VBQ</td>\n",
       "      <td>Michael Dobey</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This show always is excellent, as far as briti...</td>\n",
       "      <td>5</td>\n",
       "      <td>Robson green and great writing</td>\n",
       "      <td>1234310400</td>\n",
       "      <td>02 11, 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                    reviewerName helpful  \\\n",
       "0  A11N155CW1UV02  B000H00VBQ                        AdrianaM  [0, 0]   \n",
       "1  A3BC8O2KCL29V2  B000H00VBQ                         Carol T  [0, 0]   \n",
       "2   A60D5HQFOTSOM  B000H00VBQ  Daniel Cooper \"dancoopermedia\"  [0, 1]   \n",
       "3  A1RJPIGRSNX4PW  B000H00VBQ                  J. Kaplan \"JJ\"  [0, 0]   \n",
       "4  A16XRPF40679KG  B000H00VBQ                   Michael Dobey  [1, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  I had big expectations because I love English ...        2   \n",
       "1  I highly recommend this series. It is a must f...        5   \n",
       "2  This one is a real snoozer. Don't believe anyt...        1   \n",
       "3  Mysteries are interesting.  The tension betwee...        4   \n",
       "4  This show always is excellent, as far as briti...        5   \n",
       "\n",
       "                          summary  unixReviewTime   reviewTime  \n",
       "0      A little bit boring for me      1399075200   05 3, 2014  \n",
       "1           Excellent Grown Up TV      1346630400   09 3, 2012  \n",
       "2           Way too boring for me      1381881600  10 16, 2013  \n",
       "3     Robson Green is mesmerizing      1383091200  10 30, 2013  \n",
       "4  Robson green and great writing      1234310400  02 11, 2009  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Amazon_Instant_Video_5.json.gz\n",
    "data_reviews = pd.read_json('reviews_Amazon_Instant_Video_5.json.gz', \n",
    "                            lines=True, compression='gzip')\n",
    "data_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b934fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 37126 con 9 columnas de información\n",
      "\n",
      "Tipo de las columnas :\n",
      "reviewerID        object\n",
      "asin              object\n",
      "reviewerName      object\n",
      "helpful           object\n",
      "reviewText        object\n",
      "overall            int64\n",
      "summary           object\n",
      "unixReviewTime     int64\n",
      "reviewTime        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f'Tenemos {data_reviews.shape[0]} con {data_reviews.shape[1]} columnas de información')\n",
    "print(f'\\nTipo de las columnas :\\n{data_reviews.dtypes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e694482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nos quedamos con las columnas importantes para nuestro análisis de sentimiento\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdrianaM</td>\n",
       "      <td>A little bit boring for me</td>\n",
       "      <td>I had big expectations because I love English ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carol T</td>\n",
       "      <td>Excellent Grown Up TV</td>\n",
       "      <td>I highly recommend this series. It is a must f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daniel Cooper \"dancoopermedia\"</td>\n",
       "      <td>Way too boring for me</td>\n",
       "      <td>This one is a real snoozer. Don't believe anyt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J. Kaplan \"JJ\"</td>\n",
       "      <td>Robson Green is mesmerizing</td>\n",
       "      <td>Mysteries are interesting.  The tension betwee...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Dobey</td>\n",
       "      <td>Robson green and great writing</td>\n",
       "      <td>This show always is excellent, as far as briti...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     reviewerName                         summary  \\\n",
       "0                        AdrianaM      A little bit boring for me   \n",
       "1                         Carol T           Excellent Grown Up TV   \n",
       "2  Daniel Cooper \"dancoopermedia\"           Way too boring for me   \n",
       "3                  J. Kaplan \"JJ\"     Robson Green is mesmerizing   \n",
       "4                   Michael Dobey  Robson green and great writing   \n",
       "\n",
       "                                          reviewText  overall  \n",
       "0  I had big expectations because I love English ...        2  \n",
       "1  I highly recommend this series. It is a must f...        5  \n",
       "2  This one is a real snoozer. Don't believe anyt...        1  \n",
       "3  Mysteries are interesting.  The tension betwee...        4  \n",
       "4  This show always is excellent, as far as briti...        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reviews = data_reviews[['reviewerName', 'summary', 'reviewText', 'overall']]\n",
    "print('Nos quedamos con las columnas importantes para nuestro análisis de sentimiento')\n",
    "data_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c55da",
   "metadata": {},
   "source": [
    "### Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3efca1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función tokeniza, elimina signos de puntuación,lematiza y elimina StopWords\n",
    "def list_to_words(text):\n",
    "    words = []\n",
    "    sw_list = get_stop_words('en')\n",
    "    \n",
    "    for sentence in text:\n",
    "        \n",
    "        for word in RegexpTokenizer(r\"\\w+\").tokenize(sentence):            \n",
    "            #w = RegexpTokenizer(r\"\\w+\\'\\w+|\\w+\").tokenize(w)\n",
    "            \n",
    "            if word.lower() not in sw_list:\n",
    "                clean_word = WordNetLemmatizer().lemmatize(word).lower().strip()               \n",
    "                if clean_word.isdigit():\n",
    "                    clean_word = num2words(clean_word, lang='en')                    \n",
    "                if (len(clean_word) > 3):\n",
    "                    words.append(clean_word)\n",
    "                \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db36c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_reviews = list_to_words(data_reviews['reviewText'])\n",
    "print(len(words_in_reviews))\n",
    "print(words_in_reviews[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3efef9",
   "metadata": {},
   "source": [
    "### Cardinalidad del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc392a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = Counter(words_in_reviews)\n",
    "word_freqs.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d1bb0",
   "metadata": {},
   "source": [
    "### Distribución de reviews por número de estrellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7283f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reviews['overall'].value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e820e263",
   "metadata": {},
   "source": [
    "Vemos que más del 80% de las reviews tienen 4 o 5 estrellas\n",
    "\n",
    "Solo el 5% de las reviews tienen menos de 3 estrellas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40daf93e",
   "metadata": {},
   "source": [
    "### Nº de reviews positivas y negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_reviews[data_reviews['overall']>2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3959dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_reviews[data_reviews['overall']<3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415a264",
   "metadata": {},
   "source": [
    "### N-grams más frecuentes y Nube de Palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc233267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que devuelve lista de palabras y los bigramas,trigramas y palabras mas frecuentes\n",
    "def n_grams(stars = 0):\n",
    "    if (stars == 0):\n",
    "        words_in_reviews = list_to_words(data_reviews['reviewText'])\n",
    "    else:\n",
    "        words_in_reviews = list_to_words(\n",
    "            data_reviews[data_reviews['overall'] == stars]['reviewText']) \n",
    "    \n",
    "    bigrams = list(ngrams(words_in_reviews, 2))   \n",
    "    trigrams = list(ngrams(words_in_reviews, 3))\n",
    "    \n",
    "    return [words_in_reviews,\n",
    "            Counter(bigrams).most_common(25), \n",
    "            Counter(trigrams).most_common(25),\n",
    "            Counter(words_in_reviews).most_common(25)]\n",
    "\n",
    "# Fucion para representar histogramas\n",
    "def crear_histo (lista):\n",
    "    words3 = [str(w[0]) for w in lista]\n",
    "    freqs3 = [w[1] for w in lista]\n",
    "    freqs3, words3 = zip(*sorted(zip(freqs3, words3)))\n",
    "    plt.barh(words3, freqs3)\n",
    "    plt.show()   \n",
    "    \n",
    "# Fucion para representar Nubes de palabras   \n",
    "def plot_word_cloud(text):\n",
    "    wordcloud = WordCloud(max_font_size=50, max_words=25, background_color=\"white\").generate(' '.join(text))\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['Palabras', 'Bigramas', 'Trigramas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c8568",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram = n_grams()\n",
    "\n",
    "print(f'{text[0]} mas frecuentes para todas las reviews')\n",
    "crear_histo(n_gram[3])\n",
    "\n",
    "print ('N-grams de todas las reviews\\n')\n",
    "for j in range(1,3):\n",
    "    print(f'{text[j]} más frecuentes')\n",
    "    crear_histo(n_gram[j])\n",
    "    \n",
    "print ('Nube de palabras')\n",
    "plot_word_cloud(n_gram[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,0,-1):    \n",
    "    n_gram = n_grams(i)\n",
    "    \n",
    "    print(f'{text[0]} mas frecuentes para reviews con {i} estrellas')\n",
    "    crear_histo(n_gram[3])\n",
    "    \n",
    "    print (f'N-grams\\n')\n",
    "    for j in range(1,3):\n",
    "        print(f'{text[j]} más frecuentes')\n",
    "        crear_histo(n_gram[j])\n",
    "        \n",
    "    print ('Nube de palabras')\n",
    "    plot_word_cloud(n_gram[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece4c91",
   "metadata": {},
   "source": [
    "### Visualización en 2 dimensiones de algunos word embeddings calculados con Word2Vec y con FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7411bd63",
   "metadata": {},
   "source": [
    "Lo haremos con las reviews cinco estrellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_N = ' '.join([WordNetLemmatizer().lemmatize(word) for word in n_grams(5)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68a8d35",
   "metadata": {},
   "source": [
    "Guardamos el corpus en un .txt para volver a instanciarlo para evitar problemas del método seek() con LineSentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'w') as text_file:\n",
    "    text_file.write(sentences_N)\n",
    "corpus = LineSentence('corpus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef52524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_cluster(model, keys):\n",
    "    embedding_clusters = []\n",
    "    word_clusters = []\n",
    "    for word in keys:\n",
    "        embeddings = []\n",
    "        words = []\n",
    "        for sim in model.wv.most_similar(word, topn=10):\n",
    "            words.append(sim)\n",
    "            embeddings.append(model.wv[sim[0]])\n",
    "        embedding_clusters.append(embeddings)\n",
    "        word_clusters.append(words)\n",
    "    return embedding_clusters, word_clusters\n",
    "\n",
    "def dim_2D(embedding_clusters):\n",
    "    \n",
    "    tsne_model_2d = TSNE(perplexity=15,\n",
    "                         n_components=2,\n",
    "                         init='pca',\n",
    "                         n_iter=3500,\n",
    "                         random_state=32)\n",
    "\n",
    "    embedding_clusters = np.array(embedding_clusters)\n",
    "    n, m, k = embedding_clusters.shape\n",
    "\n",
    "    embeddings_2d = np.array(\n",
    "        tsne_model_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "    return embeddings_2d\n",
    "\n",
    "def print_sim_words(keys, word_clusters):\n",
    "    for i, key in enumerate(keys):\n",
    "        query = \"Most similar to {}\".format(key) \n",
    "        print(query)\n",
    "        print(\"-\"*len(query))\n",
    "        for sim in word_clusters[i]:\n",
    "            print(sim[0], \"......\", round(sim[1]*100, 2),\"%\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "def tsne_plot_similar_words(labels, embedding_clusters, word_clusters, a=0.7):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
    "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
    "        x = embeddings[:,0]\n",
    "        y = embeddings[:,1]\n",
    "        plt.scatter(x, y, c=[color], alpha=a, label=label)\n",
    "        for i, word in enumerate(words):\n",
    "            plt.annotate(word[0], alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2), \n",
    "                         textcoords='offset points', ha='right', va='bottom', size=8)\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.title('Representación en 2D de los embeddings de algunos clusters de palabras')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe10ff8",
   "metadata": {},
   "source": [
    "#### Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731eb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_params = {\n",
    "    'sg': 0,\n",
    "    'vector_size': 300,\n",
    "    'min_count': 5,\n",
    "    'window': 5,\n",
    "    'hs': 0,\n",
    "    'negative': 20,\n",
    "    'workers': 4\n",
    "}\n",
    "\n",
    "w2v_cbow = Word2Vec(**cbow_params)\n",
    "w2v_cbow.build_vocab(corpus)\n",
    "w2v_cbow.train(corpus, total_examples = w2v_cbow.corpus_count, epochs=10)\n",
    "w2v_cbow.save('w2v_sg_d300_mc5_w5.pkl')\n",
    "print('Vocabulario compuesto por {} palabras'.format(len(w2v_cbow.wv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['problem', 'issue', 'perfectly', 'good', 'season', 'great', 'show']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b4574",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_clusters, word_clusters = crear_cluster(w2v_cbow, keys)\n",
    "embeddings_2d = dim_2D(embedding_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sim_words(keys, word_clusters)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e324763",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot_similar_words(keys, embeddings_2d, word_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b443fec",
   "metadata": {},
   "source": [
    "#### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_params = {\n",
    "    'sg': 0,\n",
    "    'vector_size': 300,\n",
    "    'min_count': 5,\n",
    "    'window': 5,\n",
    "    'hs': 0,\n",
    "    'negative': 20,\n",
    "    'workers': 4,\n",
    "    'min_n': 3,\n",
    "    'max_n': 6\n",
    "}\n",
    "\n",
    "ft_cbow = FastText(**cbow_params)\n",
    "ft_cbow.build_vocab(corpus)\n",
    "ft_cbow.train(corpus, total_examples=ft_cbow.corpus_count, epochs=10)\n",
    "ft_cbow.save('ft_cbow_d300_mc5_w5.pkl')\n",
    "print('Vocabulario compuesto por {} palabras'.format(len(ft_cbow.wv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce207ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_clusters, word_clusters = crear_cluster(ft_cbow, keys)\n",
    "embeddings_2d = dim_2D(embedding_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sim_words(keys, word_clusters)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot_similar_words(keys, embeddings_2d, word_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41623216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
