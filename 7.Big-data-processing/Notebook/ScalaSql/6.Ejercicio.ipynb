{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a4b8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.11:4041\n",
       "SparkContext available as 'sc' (version = 3.1.2, master = local[*], app id = local-1634625863122)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbff9f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@7becb25a\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "      .builder()\n",
    "      .master(\"local[*]\")\n",
    "      .appName(\"Spark SQL KeepCoding Base\")\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e66171",
   "metadata": {},
   "source": [
    "# Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7fa344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- messages: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- data: struct (nullable = true)\n",
      " |    |    |    |-- humidity: long (nullable = true)\n",
      " |    |    |    |-- temperature: long (nullable = true)\n",
      " |    |    |-- sensor_id: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [messages: array<struct<data:struct<humidity:bigint,temperature:bigint>,sensor_id:bigint>>, source: string ... 1 more field]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//1. Pintar el schema\n",
    "val df = spark\n",
    "      .read\n",
    "      .format(\"json\")\n",
    "      .load(\"Data/exercise6/complex.json\")\n",
    "      .cache()\n",
    "\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19807fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- sensor_id: long (nullable = true)\n",
      " |-- humidity: long (nullable = true)\n",
      " |-- temperature: long (nullable = true)\n",
      "\n",
      "+----------+---------+--------+-----------+\n",
      "| timestamp|sensor_id|humidity|temperature|\n",
      "+----------+---------+--------+-----------+\n",
      "|1599758689|        1|      80|         28|\n",
      "|1599758689|        2|      80|         28|\n",
      "|1599758689|        3|      80|         28|\n",
      "|1599758749|        1|      92|         32|\n",
      "|1599758749|        2|      82|         31|\n",
      "|1599758749|        3|      70|         25|\n",
      "+----------+---------+--------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "flatDF: org.apache.spark.sql.DataFrame = [timestamp: bigint, sensor_id: bigint ... 2 more fields]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val flatDF = df.select($\"timestamp\", explode($\"messages\"))\n",
    "      .select($\"timestamp\", $\"col.sensor_id\".as(\"sensor_id\"), $\"col.data.*\")\n",
    "\n",
    "    flatDF.printSchema()\n",
    "    flatDF.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7950bda7",
   "metadata": {},
   "source": [
    "# Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933c5cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- locations: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- metrics: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- sensor_id: long (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [locations: array<string>, metrics: array<bigint> ... 2 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//1. Pintar el schema\n",
    "    val df = spark\n",
    "      .read\n",
    "      .format(\"json\")\n",
    "      .load(\"Data/exercise6/arrays.json\")\n",
    "      .cache()\n",
    "\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d7685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------------+------------------+------------------+\n",
      "| timestamp|sensor_id|        locations|array_max(metrics)|array_min(metrics)|\n",
      "+----------+---------+-----------------+------------------+------------------+\n",
      "|1599758629|        1|[ZonaA, Pasillo1]|                74|                26|\n",
      "|1599758629|        2|[ZonaB, Pasillo1]|                80|                31|\n",
      "|1599758629|        3|[ZonaA, Pasillo2]|                60|                34|\n",
      "|1599758689|        1|[ZonaA, Pasillo1]|                80|                25|\n",
      "|1599758689|        2|[ZonaB, Pasillo1]|                75|                32|\n",
      "|1599758689|        3|[ZonaA, Pasillo1]|                62|                35|\n",
      "+----------+---------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//2. Obtener el max y min de los elementos del array metrics\n",
    "    df.select($\"timestamp\", $\"sensor_id\", $\"locations\", array_max($\"metrics\"), array_min($\"metrics\"))\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68ac19ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+---------+----------+\n",
      "|        locations| metrics|sensor_id| timestamp|\n",
      "+-----------------+--------+---------+----------+\n",
      "|[ZonaA, Pasillo1]|[26, 74]|        1|1599758629|\n",
      "|[ZonaA, Pasillo2]|[34, 60]|        3|1599758629|\n",
      "|[ZonaA, Pasillo1]|[25, 80]|        1|1599758689|\n",
      "|[ZonaA, Pasillo1]|[35, 62]|        3|1599758689|\n",
      "+-----------------+--------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " //3. Obtener los datos pertenecientes a la ZonaA\n",
    "    df.where(array_contains($\"locations\", \"ZonaA\"))\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9469e073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+--------+-----------+-------+\n",
      "| timestamp|sensor_id| zona| pasillo|temperatura|humedad|\n",
      "+----------+---------+-----+--------+-----------+-------+\n",
      "|1599758629|        1|ZonaA|Pasillo1|         26|     74|\n",
      "|1599758629|        2|ZonaB|Pasillo1|         31|     80|\n",
      "|1599758629|        3|ZonaA|Pasillo2|         34|     60|\n",
      "|1599758689|        1|ZonaA|Pasillo1|         25|     80|\n",
      "|1599758689|        2|ZonaB|Pasillo1|         32|     75|\n",
      "|1599758689|        3|ZonaA|Pasillo1|         35|     62|\n",
      "+----------+---------+-----+--------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " /*\n",
    "        4. Si sabemos que:\n",
    "        * La posicion 0 de metrics es igual a temperatura\n",
    "        * La posicion 1 de metrics es igual a humedad\n",
    "        * La posicion 0 de locations es zona\n",
    "        * La posicion 1 de locations es pasillo\n",
    "     */\n",
    "    df.select($\"timestamp\", $\"sensor_id\",\n",
    "      element_at($\"locations\", 1).as(\"zona\"),\n",
    "      element_at($\"locations\", 2).as(\"pasillo\"),\n",
    "      element_at($\"metrics\", 1).as(\"temperatura\"),\n",
    "      element_at($\"metrics\", 2).as(\"humedad\")\n",
    "    ).show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207ab7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
