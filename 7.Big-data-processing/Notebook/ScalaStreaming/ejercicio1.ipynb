{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4429ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.11:4040\n",
       "SparkContext available as 'sc' (version = 3.1.2, master = local[*], app id = local-1632508324605)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import scala.concurrent.duration.DurationInt\n",
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.streaming.OutputMode\n",
       "import org.apache.spark.sql.types.{IntegerType, LongType, StructField, StructType}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.concurrent.duration.DurationInt\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.streaming.OutputMode\n",
    "import org.apache.spark.sql.types.{IntegerType, LongType, StructField, StructType}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfcbd997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@18152072\n",
       "import spark.implicits._\n",
       "archivePath: String = resources/exercise1/archive\n",
       "inputPath: String = resources/exercise1/input\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "      .builder()\n",
    "      .master(\"local[*]\")\n",
    "      .appName(\"Spark Structured Streaming KeepCoding Base\")\n",
    "      .getOrCreate()\n",
    "\n",
    "    import spark.implicits._\n",
    "\n",
    "    val archivePath = \"resources/exercise1/archive\"\n",
    "    val inputPath = \"resources/exercise1/input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a60b980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(sensor_id,IntegerType,false), StructField(temperature,IntegerType,false), StructField(humidity,IntegerType,false), StructField(timestamp,LongType,false))\n",
       "inputDF: org.apache.spark.sql.DataFrame = [sensor_id: int, temperature: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val schema = StructType(Seq(\n",
    "      StructField(\"sensor_id\", IntegerType, nullable = false),\n",
    "      StructField(\"temperature\", IntegerType, nullable = false),\n",
    "      StructField(\"humidity\", IntegerType, nullable = false),\n",
    "      StructField(\"timestamp\", LongType, nullable = false)\n",
    "    ))\n",
    "\n",
    "    val inputDF = spark\n",
    "      .readStream\n",
    "      .format(\"json\")\n",
    "      .option(\"cleanSource\", \"archive\")\n",
    "      .option(\"sourceArchiveDir\", archivePath)\n",
    "      .option(\"mode\", \"DROPMALFORMED\")\n",
    "      .schema(schema)\n",
    "      .load(inputPath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95dadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "//PARTE 1:\n",
    "val streamQuery = inputDF\n",
    "          .writeStream\n",
    "          .format(\"console\")\n",
    "          .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b3d46d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": " Unable to parse time delay '0'",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: Unable to parse time delay '0'",
      "  at org.apache.spark.sql.Dataset.liftedTree1$1(Dataset.scala:759)",
      "  at org.apache.spark.sql.Dataset.withWatermark(Dataset.scala:753)",
      "  ... 40 elided",
      "Caused by: java.lang.IllegalArgumentException: Error parsing '0' to interval, expect a unit name after '0' but hit EOL",
      "  at org.apache.spark.sql.catalyst.util.IntervalUtils$.throwIAE$1(IntervalUtils.scala:550)",
      "  at org.apache.spark.sql.catalyst.util.IntervalUtils$.stringToInterval(IntervalUtils.scala:741)",
      "  at org.apache.spark.sql.Dataset.liftedTree1$1(Dataset.scala:754)",
      "  ... 41 more",
      ""
     ]
    }
   ],
   "source": [
    " //PARTE 2:\n",
    "\n",
    "/*        val streamQuery = inputDF\n",
    "          .select($\"sensor_id\", $\"timestamp\")\n",
    "          .writeStream\n",
    "          .format(\"console\")\n",
    "          .start()*/\n",
    "\n",
    "    //PARTE 2:\n",
    "\n",
    "    val streamQuery = inputDF\n",
    "      .select(\"sensor_id\")\n",
    "      .withWatermark(\"sensor_id\",\"0\")\n",
    "      .groupBy($\"sensor_id\")\n",
    "      .count()\n",
    "      .writeStream\n",
    "      .outputMode(OutputMode.Append())\n",
    "      .format(\"console\")\n",
    "      .start()\n",
    "\n",
    "    println(s\"STATUS: ${streamQuery.status}\")\n",
    "\n",
    "   // streamQuery.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5460e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
