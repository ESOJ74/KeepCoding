{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "7_2_VGG16_Emotion_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQGSrlqY_bsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f83a71-7d4a-48f5-ea68-043a92c745c8"
      },
      "source": [
        "!tar -xf ./7_Keras_Tutorial.tar.xz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xz: (stdin): Unexpected end of input\n",
            "tar: Unexpected EOF in archive\n",
            "tar: Unexpected EOF in archive\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBnC0qns_E0E"
      },
      "source": [
        "# Keras tutorial - Emotion Detection in Images of Faces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hkq06ub_E0I"
      },
      "source": [
        "## Load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9f12Ov4_E0J",
        "outputId": "64f101c9-a3bb-4d2e-aecf-d76caaee7b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "import pydot\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from kt_utils import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8654e4e8bcb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkt_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_model' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjbDT5bc_E0J"
      },
      "source": [
        "**Note**: As you can see, we've imported a lot of functions from Keras. You can use them by calling them directly in your code. Ex: `X = Input(...)` or `X = ZeroPadding2D(...)`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6z3sGgJ_E0J"
      },
      "source": [
        "## 1 - Emotion Tracking\n",
        "\n",
        "* A nearby community health clinic is helping the local residents monitor their mental health.  \n",
        "* As part of their study, they are asking volunteers to record their emotions throughout the day.\n",
        "* To help the participants more easily track their emotions, you are asked to create an app that will classify their emotions based on some pictures that the volunteers will take of their facial expressions.\n",
        "* As a proof-of-concept, you first train your model to detect if someone's emotion is classified as \"happy\" or \"not happy.\"\n",
        "\n",
        "To build and train this model, you have gathered pictures of some volunteers in a nearby neighborhood. The dataset is labeled.\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=1dKgXwYjsA-Yws3RUtQQ3sgRWoZw08UuO\" style=\"width:550px;height:250px;\">\n",
        "\n",
        "Run the following code to normalize the dataset and learn about its shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx8LBiKE_E0J"
      },
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig/255.\n",
        "X_test = X_test_orig/255.\n",
        "\n",
        "# Reshape\n",
        "Y_train = Y_train_orig.T\n",
        "Y_test = Y_test_orig.T\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf5nsVxk_E0K"
      },
      "source": [
        "**Details of the \"Face\" dataset**:\n",
        "- Images are of shape (64,64,3)\n",
        "- Training: 600 pictures\n",
        "- Test: 150 pictures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sl9BIPwfhkJ"
      },
      "source": [
        "## 2 - Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbXI8sRAg3IH"
      },
      "source": [
        "# Resize images\n",
        "X_train = tf.image.resize(X_train, (71,71)).numpy()\n",
        "X_test = tf.image.resize(X_test, (71,71)).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btAsmzQwhJ45"
      },
      "source": [
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzs6rZyJhZ3u"
      },
      "source": [
        "input_shape = (71, 71, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrV8ySbh_E0N"
      },
      "source": [
        "## 3 - Conclusion\n",
        "\n",
        "Congratulations, you have created a proof of concept for \"happiness detection\" using pretrained models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBdqp3Zk_E0N"
      },
      "source": [
        "## 4 - Test with your own image\n",
        "\n",
        "Congratulations on finishing this exercise. You can now take a picture of your face and see if it can classify whether your expression is \"happy\" or \"not happy\". To do that:\n",
        "\n",
        "\n",
        "1. Click on \"File\" in the upper bar of this notebook, then click \"Open\".\n",
        "2. Add your image to this Jupyter Notebook's directory, in the \"images\" folder\n",
        "3. Write your image's name in the following code\n",
        "4. Run the code and check if the algorithm is right (0 is not happy, 1 is happy)!\n",
        "    \n",
        "The training/test sets were quite similar; for example, all the pictures were taken against the same background (since a front door camera is always mounted in the same position). This makes the problem easier, but a model trained on this data may or may not work on your own data. But feel free to give it a try! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkPW7lt7_E0N"
      },
      "source": [
        "### START CODE HERE ###\n",
        "img_path = 'my_image.jpg'\n",
        "### END CODE HERE ###\n",
        "img = image.load_img(img_path, target_size=(71, 71))\n",
        "imshow(img)\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "print(model.predict(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luGza13d_E0N"
      },
      "source": [
        "## 5 - Another useful function in Keras\n",
        "\n",
        "Two other basic features of Keras that you'll find useful are:\n",
        "- `model.summary()`: prints the details of your layers in a table with the sizes of its inputs/outputs\n",
        "\n",
        "Run the following code."
      ]
    }
  ]
}